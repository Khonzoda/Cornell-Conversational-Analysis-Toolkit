{
 "cells": [
  {
   "source": [
    "Computing Surprise With ConvoKit\n",
    "=====================\n",
    "This notebook provides a demo of how to use the Surprise transformer to compute surprise across a corpus. The transformer currently only allows computation of how surprising a speaker's utterances in one conversation (target) are compared to their utterances in all other conversations (context) in the corpus. Eventually, the functionality of the Surprise transformer will be abstracted to allow for computation of surprise between any target and context types."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "import numpy as np\n",
    "from convokit import Corpus, download, Surprise"
   ]
  },
  {
   "source": [
    "Step 1: Load a corpus\n",
    "--------\n",
    "For now, we will use data from the subreddit r/Cornell to demonstrate the functionality of this transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at C:\\Users\\rgang\\.convokit\\downloads\\subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download('subreddit-Cornell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Speakers: 7568\nNumber of Utterances: 74467\nNumber of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "source": [
    "In order to speed up the demo, we will take just the top 100 most active speakers (based on the number of conversations they participate in)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "SPEAKER_BLACKLIST = ['[deleted]', 'DeltaBot', 'AutoModerator']\n",
    "def utterance_is_valid(utterance):\n",
    "    return utterance.speaker.id not in SPEAKER_BLACKLIST and utterance.text"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus.organize_speaker_convo_history(utterance_filter=utterance_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_activities = corpus.get_attribute_table('speaker', ['n_convos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    n_convos\n",
       "id                          \n",
       "laveritecestla         781.0\n",
       "EQUASHNZRKUL           726.0\n",
       "CornHellUniversity     696.0\n",
       "t3hasiangod            647.0\n",
       "ilovemymemesboo        430.0\n",
       "omgdonerkebab          425.0\n",
       "cartesiancategory      341.0\n",
       "cornell256             330.0\n",
       "mushiettake            321.0\n",
       "Fencerman2             298.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_convos</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>laveritecestla</th>\n      <td>781.0</td>\n    </tr>\n    <tr>\n      <th>EQUASHNZRKUL</th>\n      <td>726.0</td>\n    </tr>\n    <tr>\n      <th>CornHellUniversity</th>\n      <td>696.0</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod</th>\n      <td>647.0</td>\n    </tr>\n    <tr>\n      <th>ilovemymemesboo</th>\n      <td>430.0</td>\n    </tr>\n    <tr>\n      <th>omgdonerkebab</th>\n      <td>425.0</td>\n    </tr>\n    <tr>\n      <th>cartesiancategory</th>\n      <td>341.0</td>\n    </tr>\n    <tr>\n      <th>cornell256</th>\n      <td>330.0</td>\n    </tr>\n    <tr>\n      <th>mushiettake</th>\n      <td>321.0</td>\n    </tr>\n    <tr>\n      <th>Fencerman2</th>\n      <td>298.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "speaker_activities.sort_values('n_convos', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers = speaker_activities.sort_values('n_convos', ascending=False).head(100).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "subset_utts = [list(corpus.get_speaker(speaker).iter_utterances()) for speaker in top_speakers]\n",
    "subset_corpus = Corpus(utterances=list(itertools.chain(*subset_utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Speakers: 100\nNumber of Utterances: 20700\nNumber of Conversations: 6904\n"
     ]
    }
   ],
   "source": [
    "subset_corpus.print_summary_stats()"
   ]
  },
  {
   "source": [
    "Step 2: Create instance of surprise transformer\n",
    "---------------\n",
    "`target_sample_size` and `context_sample_size` specify the minimum number of tokens that should be in the target and context respectively. If the target or context is too short, the transformer will set the surprise to be `nan`. If we sent these to simply be 1, the most surprising statements tend to just be the very short statements. The transformer takes `n_samples` samples from the target and context transformer (where samples are of size corresponding to `target_sample_size` and `context_sample_size`). It calculates cross entropy for each pair of samples and takes the average to get the final surprise score. This is done to minimize effect of length on scores."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = Surprise(model_key_selector=lambda utt: '_'.join([utt.speaker.id, utt.conversation_id]), target_sample_size=100, context_sample_size=100, n_samples=50, smooth=True)"
   ]
  },
  {
   "source": [
    "Step 3: Fit transformer to corpus\n",
    "-----\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = surp.fit(subset_corpus, model_text_selector=lambda utt: [u.text for u in utt.speaker.iter_utterances() if u.conversation_id != utt.conversation_id])"
   ]
  },
  {
   "source": [
    "Step 4: Transform corpus\n",
    "--------\n",
    "Currently, this transforms each utterance in the corpus adding a field to its metadata with the calculated surprise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_corpus = surp.transform(subset_corpus, 'speaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "def combine_dicts(x,y):\n",
    "    x.update(y)\n",
    "    return x\n",
    "surprise_scores = reduce(combine_dicts, transformed_corpus.get_speakers_dataframe()['meta.surprise'].values)\n",
    "suprise_series = pd.Series(surprise_scores).dropna()"
   ]
  },
  {
   "source": [
    "Analysis\n",
    "------\n",
    "Let's take a look at some of the most surprising speaker conversation involvements."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GROUP_laveritecestla_5xn5yi__MODEL_laveritecestla_5xn5yi    0.0\n",
       "GROUP_t3hasiangod_42j10n__MODEL_t3hasiangod_42j10n          0.0\n",
       "GROUP_omgdonerkebab_un9l1__MODEL_omgdonerkebab_un9l1        0.0\n",
       "GROUP_omgdonerkebab_s1r4w__MODEL_omgdonerkebab_s1r4w        0.0\n",
       "GROUP_omgdonerkebab_okz1u__MODEL_omgdonerkebab_okz1u        0.0\n",
       "GROUP_t3hasiangod_9ga17z__MODEL_t3hasiangod_9ga17z          0.0\n",
       "GROUP_t3hasiangod_9di5wb__MODEL_t3hasiangod_9di5wb          0.0\n",
       "GROUP_t3hasiangod_7v4scp__MODEL_t3hasiangod_7v4scp          0.0\n",
       "GROUP_t3hasiangod_65s66b__MODEL_t3hasiangod_65s66b          0.0\n",
       "GROUP_t3hasiangod_63iira__MODEL_t3hasiangod_63iira          0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "most_surprising = suprise_series.sort_values(ascending=False).head(10)\n",
    "most_surprising"
   ]
  },
  {
   "source": [
    "Now, let's look at some of the least surprising entries."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GROUP_Sleeppppp_7pzzzf__MODEL_Sleeppppp_7pzzzf             -0.019314\n",
       "GROUP_Sleeppppp_7jz1e0__MODEL_Sleeppppp_7jz1e0             -0.018662\n",
       "GROUP_chrissydablack_5vvc60__MODEL_chrissydablack_5vvc60   -0.016644\n",
       "GROUP_ChocolatePain_2kxu9t__MODEL_ChocolatePain_2kxu9t     -0.015071\n",
       "GROUP_Bearclawmen_7x6be6__MODEL_Bearclawmen_7x6be6         -0.014636\n",
       "GROUP_apbay_8dggog__MODEL_apbay_8dggog                     -0.013976\n",
       "GROUP_gauss_law_20_8mpz8j__MODEL_gauss_law_20_8mpz8j       -0.013570\n",
       "GROUP_soontocollege_79ytw7__MODEL_soontocollege_79ytw7     -0.012452\n",
       "GROUP_Bearclawmen_8z0gx8__MODEL_Bearclawmen_8z0gx8         -0.011894\n",
       "GROUP_apbay_8bmd6z__MODEL_apbay_8bmd6z                     -0.011775\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "least_surprising = suprise_series.sort_values(ascending=True).head(10)\n",
    "least_surprising"
   ]
  },
  {
   "source": [
    "### Comparison to SpeakerConvoDiversity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import SpeakerConvoDiversity\n",
    "\n",
    "scd = SpeakerConvoDiversity('div', select_fn=lambda df, row, aux: (df.convo_id != row.convo_id) & (df.speaker == row.speaker), speaker_cols=['n_convos'], aux_input={'n_iters': 50, 'cmp_sample_size': 100, 'ref_sample_size': 100}, verbosity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000/20700 utterances processed\n",
      "2000/20700 utterances processed\n",
      "3000/20700 utterances processed\n",
      "4000/20700 utterances processed\n",
      "5000/20700 utterances processed\n",
      "6000/20700 utterances processed\n",
      "7000/20700 utterances processed\n",
      "8000/20700 utterances processed\n",
      "9000/20700 utterances processed\n",
      "10000/20700 utterances processed\n",
      "11000/20700 utterances processed\n",
      "12000/20700 utterances processed\n",
      "13000/20700 utterances processed\n",
      "14000/20700 utterances processed\n",
      "15000/20700 utterances processed\n",
      "16000/20700 utterances processed\n",
      "17000/20700 utterances processed\n",
      "18000/20700 utterances processed\n",
      "19000/20700 utterances processed\n",
      "20000/20700 utterances processed\n",
      "20700/20700 utterances processed\n"
     ]
    }
   ],
   "source": [
    "from convokit.text_processing import TextParser\n",
    "\n",
    "tokenizer = TextParser(mode='tokenize', output_field='tokens', verbosity=1000)\n",
    "subset_corpus = tokenizer.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "joining tokens across conversation utterances\n",
      "100 / 15394\n",
      "200 / 15394\n",
      "300 / 15394\n",
      "400 / 15394\n",
      "500 / 15394\n",
      "600 / 15394\n",
      "700 / 15394\n",
      "800 / 15394\n",
      "900 / 15394\n",
      "1000 / 15394\n",
      "1100 / 15394\n",
      "1200 / 15394\n",
      "1300 / 15394\n",
      "1400 / 15394\n",
      "1500 / 15394\n",
      "1600 / 15394\n",
      "1700 / 15394\n",
      "1800 / 15394\n",
      "1900 / 15394\n",
      "2000 / 15394\n",
      "2100 / 15394\n",
      "2200 / 15394\n",
      "2300 / 15394\n",
      "2400 / 15394\n",
      "2500 / 15394\n",
      "2600 / 15394\n",
      "2700 / 15394\n",
      "2800 / 15394\n",
      "2900 / 15394\n",
      "3000 / 15394\n",
      "3100 / 15394\n",
      "3200 / 15394\n",
      "3300 / 15394\n",
      "3400 / 15394\n",
      "3500 / 15394\n",
      "3600 / 15394\n",
      "3700 / 15394\n",
      "3800 / 15394\n",
      "3900 / 15394\n",
      "4000 / 15394\n",
      "4100 / 15394\n",
      "4200 / 15394\n",
      "4300 / 15394\n",
      "4400 / 15394\n",
      "4500 / 15394\n",
      "4600 / 15394\n",
      "4700 / 15394\n",
      "4800 / 15394\n",
      "4900 / 15394\n",
      "5000 / 15394\n",
      "5100 / 15394\n",
      "5200 / 15394\n",
      "5300 / 15394\n",
      "5400 / 15394\n",
      "5500 / 15394\n",
      "5600 / 15394\n",
      "5700 / 15394\n",
      "5800 / 15394\n",
      "5900 / 15394\n",
      "6000 / 15394\n",
      "6100 / 15394\n",
      "6200 / 15394\n",
      "6300 / 15394\n",
      "6400 / 15394\n",
      "6500 / 15394\n",
      "6600 / 15394\n",
      "6700 / 15394\n",
      "6800 / 15394\n",
      "6900 / 15394\n",
      "7000 / 15394\n",
      "7100 / 15394\n",
      "7200 / 15394\n",
      "7300 / 15394\n",
      "7400 / 15394\n",
      "7500 / 15394\n",
      "7600 / 15394\n",
      "7700 / 15394\n",
      "7800 / 15394\n",
      "7900 / 15394\n",
      "8000 / 15394\n",
      "8100 / 15394\n",
      "8200 / 15394\n",
      "8300 / 15394\n",
      "8400 / 15394\n",
      "8500 / 15394\n",
      "8600 / 15394\n",
      "8700 / 15394\n",
      "8800 / 15394\n",
      "8900 / 15394\n",
      "9000 / 15394\n",
      "9100 / 15394\n",
      "9200 / 15394\n",
      "9300 / 15394\n",
      "9400 / 15394\n",
      "9500 / 15394\n",
      "9600 / 15394\n",
      "9700 / 15394\n",
      "9800 / 15394\n",
      "9900 / 15394\n",
      "10000 / 15394\n",
      "10100 / 15394\n",
      "10200 / 15394\n",
      "10300 / 15394\n",
      "10400 / 15394\n",
      "10500 / 15394\n",
      "10600 / 15394\n",
      "10700 / 15394\n",
      "10800 / 15394\n",
      "10900 / 15394\n",
      "11000 / 15394\n",
      "11100 / 15394\n",
      "11200 / 15394\n",
      "11300 / 15394\n",
      "11400 / 15394\n",
      "11500 / 15394\n",
      "11600 / 15394\n",
      "11700 / 15394\n",
      "11800 / 15394\n",
      "11900 / 15394\n",
      "12000 / 15394\n",
      "12100 / 15394\n",
      "12200 / 15394\n",
      "12300 / 15394\n",
      "12400 / 15394\n",
      "12500 / 15394\n",
      "12600 / 15394\n",
      "12700 / 15394\n",
      "12800 / 15394\n",
      "12900 / 15394\n",
      "13000 / 15394\n",
      "13100 / 15394\n",
      "13200 / 15394\n",
      "13300 / 15394\n",
      "13400 / 15394\n",
      "13500 / 15394\n",
      "13600 / 15394\n",
      "13700 / 15394\n",
      "13800 / 15394\n",
      "13900 / 15394\n",
      "14000 / 15394\n",
      "14100 / 15394\n",
      "14200 / 15394\n",
      "14300 / 15394\n",
      "14400 / 15394\n",
      "14500 / 15394\n",
      "14600 / 15394\n",
      "14700 / 15394\n",
      "14800 / 15394\n",
      "14900 / 15394\n",
      "15000 / 15394\n",
      "15100 / 15394\n",
      "15200 / 15394\n",
      "15300 / 15394\n"
     ]
    }
   ],
   "source": [
    "div_transformed = scd.transform(subset_corpus)"
   ]
  },
  {
   "source": [
    "Here are the speaker convo entries that have the highest diversity score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                   speaker convo_id  convo_idx       div\n",
       "id                                                                      \n",
       "Straight_Derpin__5kst5l    Straight_Derpin   5kst5l         34  4.587682\n",
       "Dr_Narwhal__6h08sg              Dr_Narwhal   6h08sg         75  4.532464\n",
       "SwissWatchesOnly__9hcpip  SwissWatchesOnly   9hcpip        129  4.499045\n",
       "ScottVandeberg__8tlcdl      ScottVandeberg   8tlcdl         81  4.498866\n",
       "sasha07974__8v40c1              sasha07974   8v40c1         42  4.492738\n",
       "t3hasiangod__4ufm6z            t3hasiangod   4ufm6z        262  4.486365\n",
       "agottler__9iyo8u                  agottler   9iyo8u         66  4.485832\n",
       "t3hasiangod__5v6sqb            t3hasiangod   5v6sqb        590  4.483437\n",
       "rrrrrrr1131__8l3xht            rrrrrrr1131   8l3xht         25  4.482575\n",
       "blackashi__2xxkm4                blackashi   2xxkm4          6  4.480777"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker</th>\n      <th>convo_id</th>\n      <th>convo_idx</th>\n      <th>div</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Straight_Derpin__5kst5l</th>\n      <td>Straight_Derpin</td>\n      <td>5kst5l</td>\n      <td>34</td>\n      <td>4.587682</td>\n    </tr>\n    <tr>\n      <th>Dr_Narwhal__6h08sg</th>\n      <td>Dr_Narwhal</td>\n      <td>6h08sg</td>\n      <td>75</td>\n      <td>4.532464</td>\n    </tr>\n    <tr>\n      <th>SwissWatchesOnly__9hcpip</th>\n      <td>SwissWatchesOnly</td>\n      <td>9hcpip</td>\n      <td>129</td>\n      <td>4.499045</td>\n    </tr>\n    <tr>\n      <th>ScottVandeberg__8tlcdl</th>\n      <td>ScottVandeberg</td>\n      <td>8tlcdl</td>\n      <td>81</td>\n      <td>4.498866</td>\n    </tr>\n    <tr>\n      <th>sasha07974__8v40c1</th>\n      <td>sasha07974</td>\n      <td>8v40c1</td>\n      <td>42</td>\n      <td>4.492738</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__4ufm6z</th>\n      <td>t3hasiangod</td>\n      <td>4ufm6z</td>\n      <td>262</td>\n      <td>4.486365</td>\n    </tr>\n    <tr>\n      <th>agottler__9iyo8u</th>\n      <td>agottler</td>\n      <td>9iyo8u</td>\n      <td>66</td>\n      <td>4.485832</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__5v6sqb</th>\n      <td>t3hasiangod</td>\n      <td>5v6sqb</td>\n      <td>590</td>\n      <td>4.483437</td>\n    </tr>\n    <tr>\n      <th>rrrrrrr1131__8l3xht</th>\n      <td>rrrrrrr1131</td>\n      <td>8l3xht</td>\n      <td>25</td>\n      <td>4.482575</td>\n    </tr>\n    <tr>\n      <th>blackashi__2xxkm4</th>\n      <td>blackashi</td>\n      <td>2xxkm4</td>\n      <td>6</td>\n      <td>4.480777</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "div_transformed.get_speaker_convo_attribute_table(attrs=['div']).sort_values('div', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "Notice that the diversity scores returned by `SpeakerConvoDiversity` are slightly different from the scores returned by the `Surprise` transformer. This difference can be attributed to the addition of Laplace smoothing in the `Surprise` transformer to account for out of vocabulary tokens. The `SpeakerConvoDiversity` transformer deals with OOV tokens by simply treating their count as 1. If you run the `Surprise` transformer with the `smooth` flag set to false, the transformer will treat OOV tokens the same way `SpeakerConvoDiversity` does. When run without smoothing, the `Surprise` transformer returns the same scores as `SpeakerConvoDiversity`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here are the least diverse speaker-convo entries based on the SpeakerConvoDiversity transformer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               speaker convo_id  convo_idx       div\n",
       "id                                                                  \n",
       "dedicateddan__4krfrc      dedicateddan   4krfrc         97  4.206292\n",
       "t3hasiangod__3wtoeo        t3hasiangod   3wtoeo         46  4.222424\n",
       "t3hasiangod__4ar3u0        t3hasiangod   4ar3u0         99  4.224168\n",
       "Fencerman2__90r1nf          Fencerman2   90r1nf        231  4.224307\n",
       "laveritecestla__4pylgl  laveritecestla   4pylgl         74  4.225633\n",
       "cornell256__4g9uub          cornell256   4g9uub         34  4.226449\n",
       "prov167__9n4jxi                prov167   9n4jxi        187  4.227379\n",
       "cryptkeep__3zgnom            cryptkeep   3zgnom         40  4.235582\n",
       "Fencerman2__8w4ae5          Fencerman2   8w4ae5        193  4.238139\n",
       "omgdonerkebab__81ee4f    omgdonerkebab   81ee4f        342  4.238310"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker</th>\n      <th>convo_id</th>\n      <th>convo_idx</th>\n      <th>div</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>dedicateddan__4krfrc</th>\n      <td>dedicateddan</td>\n      <td>4krfrc</td>\n      <td>97</td>\n      <td>4.206292</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__3wtoeo</th>\n      <td>t3hasiangod</td>\n      <td>3wtoeo</td>\n      <td>46</td>\n      <td>4.222424</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__4ar3u0</th>\n      <td>t3hasiangod</td>\n      <td>4ar3u0</td>\n      <td>99</td>\n      <td>4.224168</td>\n    </tr>\n    <tr>\n      <th>Fencerman2__90r1nf</th>\n      <td>Fencerman2</td>\n      <td>90r1nf</td>\n      <td>231</td>\n      <td>4.224307</td>\n    </tr>\n    <tr>\n      <th>laveritecestla__4pylgl</th>\n      <td>laveritecestla</td>\n      <td>4pylgl</td>\n      <td>74</td>\n      <td>4.225633</td>\n    </tr>\n    <tr>\n      <th>cornell256__4g9uub</th>\n      <td>cornell256</td>\n      <td>4g9uub</td>\n      <td>34</td>\n      <td>4.226449</td>\n    </tr>\n    <tr>\n      <th>prov167__9n4jxi</th>\n      <td>prov167</td>\n      <td>9n4jxi</td>\n      <td>187</td>\n      <td>4.227379</td>\n    </tr>\n    <tr>\n      <th>cryptkeep__3zgnom</th>\n      <td>cryptkeep</td>\n      <td>3zgnom</td>\n      <td>40</td>\n      <td>4.235582</td>\n    </tr>\n    <tr>\n      <th>Fencerman2__8w4ae5</th>\n      <td>Fencerman2</td>\n      <td>8w4ae5</td>\n      <td>193</td>\n      <td>4.238139</td>\n    </tr>\n    <tr>\n      <th>omgdonerkebab__81ee4f</th>\n      <td>omgdonerkebab</td>\n      <td>81ee4f</td>\n      <td>342</td>\n      <td>4.238310</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "div_transformed.get_speaker_convo_attribute_table(attrs=['div']).sort_values('div').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convokit-venv",
   "language": "python",
   "name": "convokit-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}