{
 "cells": [
  {
   "source": [
    "Computing Surprise With ConvoKit\n",
    "=====================\n",
    "This notebook provides a demo of how to use the Surprise transformer to compute surprise across a corpus. The transformer currently only allows computation of how surprising a speaker's utterances in one conversation (target) are compared to their utterances in all other conversations (context) in the corpus. Eventually, the functionality of the Surprise transformer will be abstracted to allow for computation of surprise between any target and context types."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import convokit\n",
    "import numpy as np\n",
    "from convokit import Corpus, download, Surprise"
   ]
  },
  {
   "source": [
    "Step 1: Load a corpus\n",
    "--------\n",
    "For now, we will use data from the subreddit r/Cornell to demonstrate the functionality of this transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset already exists at C:\\Users\\rgang\\.convokit\\downloads\\subreddit-Cornell\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(filename=download('subreddit-Cornell'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Speakers: 7568\nNumber of Utterances: 74467\nNumber of Conversations: 10744\n"
     ]
    }
   ],
   "source": [
    "corpus.print_summary_stats()"
   ]
  },
  {
   "source": [
    "In order to speed up the demo, we will take just the top 100 most active speakers (based on the number of conversations they participate in)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "SPEAKER_BLACKLIST = ['[deleted]', 'DeltaBot', 'AutoModerator']\n",
    "def utterance_is_valid(utterance):\n",
    "    return utterance.speaker.id not in SPEAKER_BLACKLIST and utterance.text"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus.organize_speaker_convo_history(utterance_filter=utterance_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_activities = corpus.get_attribute_table('speaker', ['n_convos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    n_convos\n",
       "id                          \n",
       "laveritecestla         781.0\n",
       "EQUASHNZRKUL           726.0\n",
       "CornHellUniversity     696.0\n",
       "t3hasiangod            647.0\n",
       "ilovemymemesboo        430.0\n",
       "omgdonerkebab          425.0\n",
       "cartesiancategory      341.0\n",
       "cornell256             330.0\n",
       "mushiettake            321.0\n",
       "Fencerman2             298.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_convos</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>laveritecestla</th>\n      <td>781.0</td>\n    </tr>\n    <tr>\n      <th>EQUASHNZRKUL</th>\n      <td>726.0</td>\n    </tr>\n    <tr>\n      <th>CornHellUniversity</th>\n      <td>696.0</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod</th>\n      <td>647.0</td>\n    </tr>\n    <tr>\n      <th>ilovemymemesboo</th>\n      <td>430.0</td>\n    </tr>\n    <tr>\n      <th>omgdonerkebab</th>\n      <td>425.0</td>\n    </tr>\n    <tr>\n      <th>cartesiancategory</th>\n      <td>341.0</td>\n    </tr>\n    <tr>\n      <th>cornell256</th>\n      <td>330.0</td>\n    </tr>\n    <tr>\n      <th>mushiettake</th>\n      <td>321.0</td>\n    </tr>\n    <tr>\n      <th>Fencerman2</th>\n      <td>298.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "speaker_activities.sort_values('n_convos', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_speakers = speaker_activities.sort_values('n_convos', ascending=False).head(100).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "subset_utts = [list(corpus.get_speaker(speaker).iter_utterances()) for speaker in top_speakers]\n",
    "subset_corpus = Corpus(utterances=list(itertools.chain(*subset_utts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Speakers: 100\nNumber of Utterances: 20700\nNumber of Conversations: 6904\n"
     ]
    }
   ],
   "source": [
    "subset_corpus.print_summary_stats()"
   ]
  },
  {
   "source": [
    "Step 2: Create instance of surprise transformer\n",
    "---------------\n",
    "`target_sample_size` and `context_sample_size` specify the minimum number of tokens that should be in the target and context respectively. If the target or context is too short, the transformer will set the surprise to be `nan`. If we sent these to simply be 1, the most surprising statements tend to just be the very short statements. The transformer takes `n_samples` samples from the target and context transformer (where samples are of size corresponding to `target_sample_size` and `context_sample_size`). It calculates cross entropy for each pair of samples and takes the average to get the final surprise score. This is done to minimize effect of length on scores.\n",
    "\n",
    "`model_key_selector` defines how utterances in a corpus should be mapped to a model. It takes in an utterance and returns the key for the corresponding model. For this demo we want to map utterances to models based on their speaker and conversation ids."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = Surprise(model_key_selector=lambda utt: '_'.join([utt.speaker.id, utt.conversation_id]), target_sample_size=100, context_sample_size=100, n_samples=50, smooth=True)"
   ]
  },
  {
   "source": [
    "Step 3: Fit transformer to corpus\n",
    "-----\n",
    "The `text_func` parameter defines what text each model should be trained on. For this demo, we want a model corresponding to a (speaker, conversation) pair to be trained on all the utterances from the same speaker in different conversations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "surp = surp.fit(subset_corpus, text_func=lambda utt: [u.text for u in utt.speaker.iter_utterances() if u.conversation_id != utt.conversation_id])"
   ]
  },
  {
   "source": [
    "Step 4: Transform corpus\n",
    "--------\n",
    "We'll call `transform` with object type `'speaker'` so that surprise scores will be added as a metadata field for each speaker."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_corpus = surp.transform(subset_corpus, 'speaker')"
   ]
  },
  {
   "source": [
    "Analysis\n",
    "------\n",
    "Let's take a look at some of the most surprising speaker conversation involvements."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "def combine_dicts(x,y):\n",
    "    x.update(y)\n",
    "    return x\n",
    "surprise_scores = reduce(combine_dicts, transformed_corpus.get_speakers_dataframe()['meta.surprise'].values)\n",
    "suprise_series = pd.Series(surprise_scores).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GROUP_cartesiancategory_6pot7n__MODEL_cartesiancategory_6pot7n    5.231371\n",
       "GROUP_t3hasiangod_4f56qv__MODEL_t3hasiangod_4f56qv                5.231347\n",
       "GROUP_t3hasiangod_3sc927__MODEL_t3hasiangod_3sc927                5.225886\n",
       "GROUP_t3hasiangod_3t9lgm__MODEL_t3hasiangod_3t9lgm                5.225873\n",
       "GROUP_t3hasiangod_5641lt__MODEL_t3hasiangod_5641lt                5.222505\n",
       "GROUP_t3hasiangod_5fqbes__MODEL_t3hasiangod_5fqbes                5.222256\n",
       "GROUP_t3hasiangod_4tymy0__MODEL_t3hasiangod_4tymy0                5.221537\n",
       "GROUP_t3hasiangod_57ci9e__MODEL_t3hasiangod_57ci9e                5.219757\n",
       "GROUP_t3hasiangod_5v6s6m__MODEL_t3hasiangod_5v6s6m                5.215703\n",
       "GROUP_EQUASHNZRKUL_59sn56__MODEL_EQUASHNZRKUL_59sn56              5.215699\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "most_surprising = suprise_series.sort_values(ascending=False).head(10)\n",
    "most_surprising"
   ]
  },
  {
   "source": [
    "Now, let's look at some of the least surprising entries."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GROUP_apbay_8bmd6z__MODEL_apbay_8bmd6z                      4.199647\n",
       "GROUP_Sleeppppp_7jz1e0__MODEL_Sleeppppp_7jz1e0              4.265192\n",
       "GROUP_Sleeppppp_7ldk9w__MODEL_Sleeppppp_7ldk9w              4.267883\n",
       "GROUP_chrissydablack_5vvc60__MODEL_chrissydablack_5vvc60    4.336837\n",
       "GROUP_ChocolatePain_2kxu9t__MODEL_ChocolatePain_2kxu9t      4.440125\n",
       "GROUP_Bearclawmen_8z0gx8__MODEL_Bearclawmen_8z0gx8          4.474428\n",
       "GROUP_Bearclawmen_91yv8u__MODEL_Bearclawmen_91yv8u          4.479524\n",
       "GROUP_apbay_4f3ko9__MODEL_apbay_4f3ko9                      4.483573\n",
       "GROUP_BuildAnything_8rf7j1__MODEL_BuildAnything_8rf7j1      4.487007\n",
       "GROUP_soontocollege_4retr6__MODEL_soontocollege_4retr6      4.495519\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "least_surprising = suprise_series.sort_values(ascending=True).head(10)\n",
    "least_surprising"
   ]
  },
  {
   "source": [
    "### Comparison to SpeakerConvoDiversity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convokit import SpeakerConvoDiversity\n",
    "\n",
    "scd = SpeakerConvoDiversity('div', select_fn=lambda df, row, aux: (df.convo_id != row.convo_id) & (df.speaker == row.speaker), speaker_cols=['n_convos'], aux_input={'n_iters': 50, 'cmp_sample_size': 100, 'ref_sample_size': 100}, verbosity=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000/20700 utterances processed\n",
      "2000/20700 utterances processed\n",
      "3000/20700 utterances processed\n",
      "4000/20700 utterances processed\n",
      "5000/20700 utterances processed\n",
      "6000/20700 utterances processed\n",
      "7000/20700 utterances processed\n",
      "8000/20700 utterances processed\n",
      "9000/20700 utterances processed\n",
      "10000/20700 utterances processed\n",
      "11000/20700 utterances processed\n",
      "12000/20700 utterances processed\n",
      "13000/20700 utterances processed\n",
      "14000/20700 utterances processed\n",
      "15000/20700 utterances processed\n",
      "16000/20700 utterances processed\n",
      "17000/20700 utterances processed\n",
      "18000/20700 utterances processed\n",
      "19000/20700 utterances processed\n",
      "20000/20700 utterances processed\n",
      "20700/20700 utterances processed\n"
     ]
    }
   ],
   "source": [
    "from convokit.text_processing import TextParser\n",
    "\n",
    "tokenizer = TextParser(mode='tokenize', output_field='tokens', verbosity=1000)\n",
    "subset_corpus = tokenizer.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "joining tokens across conversation utterances\n",
      "100 / 15394\n",
      "200 / 15394\n",
      "300 / 15394\n",
      "400 / 15394\n",
      "500 / 15394\n",
      "600 / 15394\n",
      "700 / 15394\n",
      "800 / 15394\n",
      "900 / 15394\n",
      "1000 / 15394\n",
      "1100 / 15394\n",
      "1200 / 15394\n",
      "1300 / 15394\n",
      "1400 / 15394\n",
      "1500 / 15394\n",
      "1600 / 15394\n",
      "1700 / 15394\n",
      "1800 / 15394\n",
      "1900 / 15394\n",
      "2000 / 15394\n",
      "2100 / 15394\n",
      "2200 / 15394\n",
      "2300 / 15394\n",
      "2400 / 15394\n",
      "2500 / 15394\n",
      "2600 / 15394\n",
      "2700 / 15394\n",
      "2800 / 15394\n",
      "2900 / 15394\n",
      "3000 / 15394\n",
      "3100 / 15394\n",
      "3200 / 15394\n",
      "3300 / 15394\n",
      "3400 / 15394\n",
      "3500 / 15394\n",
      "3600 / 15394\n",
      "3700 / 15394\n",
      "3800 / 15394\n",
      "3900 / 15394\n",
      "4000 / 15394\n",
      "4100 / 15394\n",
      "4200 / 15394\n",
      "4300 / 15394\n",
      "4400 / 15394\n",
      "4500 / 15394\n",
      "4600 / 15394\n",
      "4700 / 15394\n",
      "4800 / 15394\n",
      "4900 / 15394\n",
      "5000 / 15394\n",
      "5100 / 15394\n",
      "5200 / 15394\n",
      "5300 / 15394\n",
      "5400 / 15394\n",
      "5500 / 15394\n",
      "5600 / 15394\n",
      "5700 / 15394\n",
      "5800 / 15394\n",
      "5900 / 15394\n",
      "6000 / 15394\n",
      "6100 / 15394\n",
      "6200 / 15394\n",
      "6300 / 15394\n",
      "6400 / 15394\n",
      "6500 / 15394\n",
      "6600 / 15394\n",
      "6700 / 15394\n",
      "6800 / 15394\n",
      "6900 / 15394\n",
      "7000 / 15394\n",
      "7100 / 15394\n",
      "7200 / 15394\n",
      "7300 / 15394\n",
      "7400 / 15394\n",
      "7500 / 15394\n",
      "7600 / 15394\n",
      "7700 / 15394\n",
      "7800 / 15394\n",
      "7900 / 15394\n",
      "8000 / 15394\n",
      "8100 / 15394\n",
      "8200 / 15394\n",
      "8300 / 15394\n",
      "8400 / 15394\n",
      "8500 / 15394\n",
      "8600 / 15394\n",
      "8700 / 15394\n",
      "8800 / 15394\n",
      "8900 / 15394\n",
      "9000 / 15394\n",
      "9100 / 15394\n",
      "9200 / 15394\n",
      "9300 / 15394\n",
      "9400 / 15394\n",
      "9500 / 15394\n",
      "9600 / 15394\n",
      "9700 / 15394\n",
      "9800 / 15394\n",
      "9900 / 15394\n",
      "10000 / 15394\n",
      "10100 / 15394\n",
      "10200 / 15394\n",
      "10300 / 15394\n",
      "10400 / 15394\n",
      "10500 / 15394\n",
      "10600 / 15394\n",
      "10700 / 15394\n",
      "10800 / 15394\n",
      "10900 / 15394\n",
      "11000 / 15394\n",
      "11100 / 15394\n",
      "11200 / 15394\n",
      "11300 / 15394\n",
      "11400 / 15394\n",
      "11500 / 15394\n",
      "11600 / 15394\n",
      "11700 / 15394\n",
      "11800 / 15394\n",
      "11900 / 15394\n",
      "12000 / 15394\n",
      "12100 / 15394\n",
      "12200 / 15394\n",
      "12300 / 15394\n",
      "12400 / 15394\n",
      "12500 / 15394\n",
      "12600 / 15394\n",
      "12700 / 15394\n",
      "12800 / 15394\n",
      "12900 / 15394\n",
      "13000 / 15394\n",
      "13100 / 15394\n",
      "13200 / 15394\n",
      "13300 / 15394\n",
      "13400 / 15394\n",
      "13500 / 15394\n",
      "13600 / 15394\n",
      "13700 / 15394\n",
      "13800 / 15394\n",
      "13900 / 15394\n",
      "14000 / 15394\n",
      "14100 / 15394\n",
      "14200 / 15394\n",
      "14300 / 15394\n",
      "14400 / 15394\n",
      "14500 / 15394\n",
      "14600 / 15394\n",
      "14700 / 15394\n",
      "14800 / 15394\n",
      "14900 / 15394\n",
      "15000 / 15394\n",
      "15100 / 15394\n",
      "15200 / 15394\n",
      "15300 / 15394\n"
     ]
    }
   ],
   "source": [
    "div_transformed = scd.transform(subset_corpus)"
   ]
  },
  {
   "source": [
    "Here are the speaker convo entries that have the highest diversity score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     speaker convo_id  convo_idx       div\n",
       "id                                                                        \n",
       "Straight_Derpin__5kst5l      Straight_Derpin   5kst5l         34  4.589730\n",
       "Dr_Narwhal__6h08sg                Dr_Narwhal   6h08sg         75  4.543916\n",
       "SwissWatchesOnly__9hcpip    SwissWatchesOnly   9hcpip        129  4.494886\n",
       "t3hasiangod__5v6sqb              t3hasiangod   5v6sqb        590  4.492267\n",
       "rrrrrrr1131__8l3xht              rrrrrrr1131   8l3xht         25  4.487745\n",
       "sasha07974__8v40c1                sasha07974   8v40c1         42  4.486570\n",
       "agottler__9iyo8u                    agottler   9iyo8u         66  4.483837\n",
       "ScottVandeberg__8tlcdl        ScottVandeberg   8tlcdl         81  4.480680\n",
       "t3hasiangod__4ufm6z              t3hasiangod   4ufm6z        262  4.480016\n",
       "cartesiancategory__8bdf5g  cartesiancategory   8bdf5g        310  4.478022"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker</th>\n      <th>convo_id</th>\n      <th>convo_idx</th>\n      <th>div</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Straight_Derpin__5kst5l</th>\n      <td>Straight_Derpin</td>\n      <td>5kst5l</td>\n      <td>34</td>\n      <td>4.589730</td>\n    </tr>\n    <tr>\n      <th>Dr_Narwhal__6h08sg</th>\n      <td>Dr_Narwhal</td>\n      <td>6h08sg</td>\n      <td>75</td>\n      <td>4.543916</td>\n    </tr>\n    <tr>\n      <th>SwissWatchesOnly__9hcpip</th>\n      <td>SwissWatchesOnly</td>\n      <td>9hcpip</td>\n      <td>129</td>\n      <td>4.494886</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__5v6sqb</th>\n      <td>t3hasiangod</td>\n      <td>5v6sqb</td>\n      <td>590</td>\n      <td>4.492267</td>\n    </tr>\n    <tr>\n      <th>rrrrrrr1131__8l3xht</th>\n      <td>rrrrrrr1131</td>\n      <td>8l3xht</td>\n      <td>25</td>\n      <td>4.487745</td>\n    </tr>\n    <tr>\n      <th>sasha07974__8v40c1</th>\n      <td>sasha07974</td>\n      <td>8v40c1</td>\n      <td>42</td>\n      <td>4.486570</td>\n    </tr>\n    <tr>\n      <th>agottler__9iyo8u</th>\n      <td>agottler</td>\n      <td>9iyo8u</td>\n      <td>66</td>\n      <td>4.483837</td>\n    </tr>\n    <tr>\n      <th>ScottVandeberg__8tlcdl</th>\n      <td>ScottVandeberg</td>\n      <td>8tlcdl</td>\n      <td>81</td>\n      <td>4.480680</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__4ufm6z</th>\n      <td>t3hasiangod</td>\n      <td>4ufm6z</td>\n      <td>262</td>\n      <td>4.480016</td>\n    </tr>\n    <tr>\n      <th>cartesiancategory__8bdf5g</th>\n      <td>cartesiancategory</td>\n      <td>8bdf5g</td>\n      <td>310</td>\n      <td>4.478022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "div_transformed.get_speaker_convo_attribute_table(attrs=['div']).sort_values('div', ascending=False).head(10)"
   ]
  },
  {
   "source": [
    "Notice that the diversity scores returned by `SpeakerConvoDiversity` are slightly different from the scores returned by the `Surprise` transformer. This difference can be attributed to the addition of Laplace smoothing in the `Surprise` transformer to account for out of vocabulary tokens. The `SpeakerConvoDiversity` transformer deals with OOV tokens by simply treating their count as 1. If you run the `Surprise` transformer with the `smooth` flag set to false, the transformer will treat OOV tokens the same way `SpeakerConvoDiversity` does. When run without smoothing, the `Surprise` transformer returns the same scores as `SpeakerConvoDiversity`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Here are the least diverse speaker-convo entries based on the SpeakerConvoDiversity transformer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                               speaker convo_id  convo_idx       div\n",
       "id                                                                  \n",
       "Fencerman2__6tiomd          Fencerman2   6tiomd        111  4.203668\n",
       "t3hasiangod__3wtoeo        t3hasiangod   3wtoeo         46  4.221644\n",
       "iBeReese__1uuldh              iBeReese   1uuldh          6  4.223295\n",
       "Enyo287__5ipedu                Enyo287   5ipedu        281  4.225254\n",
       "laveritecestla__4pylgl  laveritecestla   4pylgl         74  4.225618\n",
       "dedicateddan__4krfrc      dedicateddan   4krfrc         97  4.228558\n",
       "Pjcrafty__5apodz              Pjcrafty   5apodz         17  4.230794\n",
       "t3hasiangod__4ar3u0        t3hasiangod   4ar3u0         99  4.231619\n",
       "kickstand__obvjl             kickstand    obvjl          6  4.235342\n",
       "shadowclan98__6njs8z      shadowclan98   6njs8z          8  4.238192"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>speaker</th>\n      <th>convo_id</th>\n      <th>convo_idx</th>\n      <th>div</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fencerman2__6tiomd</th>\n      <td>Fencerman2</td>\n      <td>6tiomd</td>\n      <td>111</td>\n      <td>4.203668</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__3wtoeo</th>\n      <td>t3hasiangod</td>\n      <td>3wtoeo</td>\n      <td>46</td>\n      <td>4.221644</td>\n    </tr>\n    <tr>\n      <th>iBeReese__1uuldh</th>\n      <td>iBeReese</td>\n      <td>1uuldh</td>\n      <td>6</td>\n      <td>4.223295</td>\n    </tr>\n    <tr>\n      <th>Enyo287__5ipedu</th>\n      <td>Enyo287</td>\n      <td>5ipedu</td>\n      <td>281</td>\n      <td>4.225254</td>\n    </tr>\n    <tr>\n      <th>laveritecestla__4pylgl</th>\n      <td>laveritecestla</td>\n      <td>4pylgl</td>\n      <td>74</td>\n      <td>4.225618</td>\n    </tr>\n    <tr>\n      <th>dedicateddan__4krfrc</th>\n      <td>dedicateddan</td>\n      <td>4krfrc</td>\n      <td>97</td>\n      <td>4.228558</td>\n    </tr>\n    <tr>\n      <th>Pjcrafty__5apodz</th>\n      <td>Pjcrafty</td>\n      <td>5apodz</td>\n      <td>17</td>\n      <td>4.230794</td>\n    </tr>\n    <tr>\n      <th>t3hasiangod__4ar3u0</th>\n      <td>t3hasiangod</td>\n      <td>4ar3u0</td>\n      <td>99</td>\n      <td>4.231619</td>\n    </tr>\n    <tr>\n      <th>kickstand__obvjl</th>\n      <td>kickstand</td>\n      <td>obvjl</td>\n      <td>6</td>\n      <td>4.235342</td>\n    </tr>\n    <tr>\n      <th>shadowclan98__6njs8z</th>\n      <td>shadowclan98</td>\n      <td>6njs8z</td>\n      <td>8</td>\n      <td>4.238192</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "div_transformed.get_speaker_convo_attribute_table(attrs=['div']).sort_values('div').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<convokit.model.corpus.Corpus at 0x1dd3e8ac8c8>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "from convokit.speaker_convo_helpers.speaker_convo_lifestage import SpeakerConvoLifestage\n",
    "\n",
    "lifestage_transform = SpeakerConvoLifestage(20)\n",
    "lifestage_transform.transform(subset_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "subset_corpus.get_speaker_convo_info('laveritecestla', '5xn5yi', key='lifestage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convokit-venv",
   "language": "python",
   "name": "convokit-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}